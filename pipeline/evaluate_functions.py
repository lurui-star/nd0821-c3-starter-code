"""
Author: Rui Lu
Date: December, 2024
This script holds the model evaluation function
"""

from sklearn.metrics import roc_curve,accuracy_score,f1_score,fbeta_score,recall_score,precision_score, auc
import pandas as pd

def compute_model_metrics(y, preds, pred_prob, slice_display=False):
    """
    Validates the trained machine learning model using precision, recall, F1, and ROC AUC.

    Inputs
    ------
    y : np.array
        Known labels, binarized.
    preds : np.array
        Predicted labels or predicted probabilities (binarized).
    pred_prob : np.array
        Predicted probabilities for the positive class.
    slice_display: bool, optional
        If True, returns only precision, recall, and F-beta score.

    Returns
    -------
    dict
        A dictionary containing the computed metrics:
        - precision : float
        - recall : float
        - fbeta : float
        - fpr : np.array
        - tpr : np.array
        - roc_auc : float
    """
    # Check if predicted probabilities are multidimensional and take the positive class probabilities
    if len(pred_prob.shape) > 1:
        pred_prob = pred_prob[:, 1]  # Use probability of class 1 (positive class)

    # Calculate precision, recall, and F-beta score using class labels
    precision = round(precision_score(y, preds, zero_division=1), 2)
    recall = round(recall_score(y, preds, zero_division=1), 2)
    fbeta = round(fbeta_score(y, preds, beta=1, zero_division=1), 2)
    
    # Calculate ROC metrics using predicted probabilities
    fpr, tpr, thresholds = roc_curve(y, pred_prob)
    roc_auc = auc(fpr, tpr)
    
    # Return only precision, recall, and fbeta if slice_display is True
    if slice_display:
        return {'precision': precision, 'recall': recall, 'fbeta': fbeta}
    
    # Return all metrics if slice_display is False
    return {
        'precision': precision,
        'recall': recall,
        'fbeta': fbeta,
        'fpr': fpr,
        'tpr': tpr,
        'roc_auc': roc_auc
    }


def slice_compute_model_metrics(X, y, Y_pred, Y_pred_prob, categorical_features, output_dir):
    """
    Computes model evaluation metrics for different slices of a dataset based on categorical features.

    This function loops through the categorical features in the dataset, computes evaluation metrics
    (such as accuracy, precision, recall, etc.) for each slice (unique value) of the categorical features,
    and saves the results into a text file.

    Parameters:
    ----------
    X : pd.DataFrame
        The input feature DataFrame where each column represents a feature in the dataset.
        The categorical features used for slicing will be extracted from this DataFrame.
        
    y : pd.Series or pd.DataFrame
        The target variable (true labels) associated with the input features.
        
    Y_pred : np.array
        The predicted values generated by the model for the target variable.
        
    Y_pred_prob : np.array
        The predicted probabilities generated by the model, where the second column corresponds to the probability 
        of the positive class in binary classification.
        
    categorical_features : list of str
        A list of column names (strings) representing the categorical features in the dataset.
        The function will compute metrics for each unique value in these features.

    output_dir : str
        The directory path where the output text file (`slice_output.txt`) will be saved.
        
    Returns:
    -------
    slice_result_dict : dict
        A dictionary where the keys are the categorical feature names, and the values are another dictionary
        containing the computed metrics for each unique value of the categorical feature.
        The metrics include evaluation results for each slice, which could include accuracy, precision, recall, etc.
    """
    
    slice_result_dict = {}

    # Loop through each categorical feature
    for item in categorical_features:
        # Create a new DataFrame with categorical feature and target variable 'salary'
        df_new = pd.concat([X[item].copy(), y], axis=1)
        df_new['pred_salary'] = Y_pred
        df_new['pred_salary_prob'] = Y_pred_prob[:, 1]

        # Group by the categorical feature and compute metrics for each slice
        slice_result_dict[item] = df_new.groupby(item).apply(
            lambda group: compute_model_metrics(group['salary'], group['pred_salary'], group['pred_salary_prob'], slice_display=True)
        )

    # Prepare the output text
    output_text = ""

    # Format the results as a string to write into the file
    for feature, result in slice_result_dict.items():
        output_text += f"'{feature}':\n"
        for value, metrics in result.items():
            output_text += f"  {value}: {metrics}\n"

    # Save the output to the specified file
    output_file_path = f"{output_dir}/slice_output.txt"
    with open(output_file_path, 'w') as f:
        f.write(output_text)

    # Return the dictionary containing metrics for each feature slice
    return slice_result_dict
