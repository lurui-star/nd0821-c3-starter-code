{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb839e61-0975-4d73-b02e-e7f4c22856c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "# Data processing\n",
    "from pipeline.data import import_data, process_data\n",
    "\n",
    "# Model training and evaluation\n",
    "from pipeline.model import train_model, train\n",
    "from pipeline.run_evaluation import run_evaluate_model\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0f95fb-8b5c-437d-90ec-c5e7e63fcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(file_path, file_name):\n",
    "    return os.path.exists(os.path.join(os.path.abspath(file_path), file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40dcebc0-5533-4157-9582-e921a6beb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db60c246-c4db-40c2-8f4b-8e82fd2b4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_config(model_config: dict):\n",
    "    \"\"\"Given a model configuration dict, return the corresponding model instance.\"\"\"\n",
    "\n",
    "    if \"XGBClassifier\" in model_config:\n",
    "        model_params = model_config[\"XGBClassifier\"]\n",
    "        model = XGBClassifier(**model_params)  # Use parameters from config\n",
    "        return model\n",
    "\n",
    "    elif \"LogisticRegression\" in model_config:\n",
    "        model_params = model_config[\"LogisticRegression\"]\n",
    "        model = LogisticRegression(**model_params)  # Use parameters from config\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87623a87-8adc-4ec9-a422-d37262279bfc",
   "metadata": {},
   "source": [
    "### prepare for test data and train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfb9de1-49ae-4b94-b458-3635e6636dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture(scope=\"session\")\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Data loaded from csv file used for tests\n",
    "\n",
    "    Returns:\n",
    "       X and y for tests\n",
    "    \"\"\"\n",
    "    if not os.path.exists(config[\"main\"][\"data\"][\"pth\"]):\n",
    "        pytest.fail(f\"Data not found at path: {config['main']['data']['pth']}\")\n",
    "    df = import_data(config[\"main\"][\"data\"][\"pth\"])\n",
    "\n",
    "    X, y = process_data(\n",
    "        df,\n",
    "        config[\"main\"][\"data\"][\"categorical_features\"],\n",
    "        config[\"main\"][\"data\"][\"label\"],\n",
    "    )\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f14215-a818-48b3-bff9-33f967edc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture(scope=\"session\")\n",
    "def train_test_split(load_data):\n",
    "    if not os.path.exists(config[\"main\"][\"data\"][\"pth\"]):\n",
    "        pytest.fail(f\"Data not found at path: {config['main']['data']['pth']}\")\n",
    "\n",
    "    df = import_data(config[\"main\"][\"data\"][\"pth\"])\n",
    "    X, y = process_data(\n",
    "        df,\n",
    "        config[\"main\"][\"data\"][\"categorical_features\"],\n",
    "        config[\"main\"][\"data\"][\"label\"],\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=config[\"main\"][\"train_test_split\"][\"test_size\"],\n",
    "        random_state=config[\"main\"][\"train_test_split\"][\"random_state\"],\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfb068-ee39-45cf-b4a1-bf2a9ef77d7a",
   "metadata": {},
   "source": [
    "### Start test section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee864c59-66c3-479e-8fa4-3c3a93f6ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_columns_exist(load_data):\n",
    "    \"\"\"\n",
    "    Test if all expected columns exist in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "      load_data: Data to be tested (pandas DataFrame)\n",
    "    \"\"\"\n",
    "    # Assume load_data is a DataFrame or similar structure\n",
    "    X, y = load_data  # load_data is passed automatically by pytest as a fixture\n",
    "\n",
    "    # List of expected columns\n",
    "    expected_columns = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlgt\",\n",
    "        \"education\",\n",
    "        \"education_num\",\n",
    "        \"marital_status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per_week\",\n",
    "        \"native-country\",\n",
    "        \"salary\",\n",
    "    ]\n",
    "\n",
    "    # Check if each expected column is in the DataFrame\n",
    "    for column in expected_columns:\n",
    "        assert column in X.columns, f\"Column '{column}' is missing in the DataFrame.\"\n",
    "\n",
    "    # If necessary, you can also print out the columns that were found for verification\n",
    "    print(\"Found columns in DataFrame:\", X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "946d6845-a41a-4236-8d57-208935ccdc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.16s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest --maxfail=1 --disable-warnings -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d88828-d671-4aeb-a81a-cd7f94625878",
   "metadata": {},
   "source": [
    "### Test for train section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "018b1210-073a-4297-89fe-f3c49186c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 11:48:24,748 Downloading data set\n",
      "2024-12-30 11:48:24,824 Handle categorical features\n",
      "2024-12-30 11:48:24,888 Encode response variable\n"
     ]
    }
   ],
   "source": [
    "df = import_data(pth=config[\"main\"][\"data\"][\"pth\"])\n",
    "X, y = process_data(\n",
    "    df,\n",
    "    config[\"main\"][\"data\"][\"categorical_features\"],\n",
    "    config[\"main\"][\"data\"][\"label\"],\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=config[\"main\"][\"train_test_split\"][\"test_size\"],\n",
    "    random_state=config[\"main\"][\"train_test_split\"][\"random_state\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8737ccaa-3c62-48b2-a949-37dd38e6e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_and_evaluate_model(X_train, X_test, y_train, y_test, config):\n",
    "    try:\n",
    "        model = get_model_from_config(config[\"main\"][\"modeling\"][\"MODEL\"])\n",
    "        best_model, best_params = train(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            config[\"main\"][\"modeling\"][\"param_grid\"],\n",
    "            config[\"main\"][\"modeling\"][\"FEATURES\"],\n",
    "        )\n",
    "\n",
    "        run_evaluate_model(\n",
    "            y_test,\n",
    "            best_model,\n",
    "            X_test,\n",
    "            output_dir=os.getcwd() + config[\"main\"][\"modeling\"][\"output_dir\"],\n",
    "            model_dir=os.getcwd() + config[\"main\"][\"modeling\"][\"model_dir\"],\n",
    "            slice_evaluation_by_feature=config[\"main\"][\"modeling\"][\"slice_output\"][\n",
    "                \"slice_evaluation_by_feature\"\n",
    "            ],\n",
    "            categorical_features=config[\"main\"][\"modeling\"][\"slice_output\"][\n",
    "                \"categorical_features\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        logging.info(\"SUCCESS: Training and evaluating model\")\n",
    "\n",
    "    except BaseException as e:\n",
    "        logging.error(\"ERROR: Model training/evaluating failed. %s\", str(e))\n",
    "\n",
    "    model_name = \"best_model.pkl\"\n",
    "    try:\n",
    "        model_path = os.getcwd() + config[\"main\"][\"modeling\"][\"model_dir\"]\n",
    "        assert check_file_exists(model_path, model_name)\n",
    "        logging.info(\"SUCCESS: Best model %s is saved.\", model_name)\n",
    "    except AssertionError:\n",
    "        logging.error(\n",
    "            \"ERROR: Best model %s not found in path %s.\",\n",
    "            model_name,\n",
    "            model_path,\n",
    "        )\n",
    "\n",
    "    # Check if ROC image exists\n",
    "    roc_image_name = \"roc_curve.png\"\n",
    "    try:\n",
    "        image_path = os.getcwd() + config[\"main\"][\"modeling\"][\"output_dir\"]\n",
    "        assert check_file_exists(image_path, roc_image_name)\n",
    "        logging.info(\"SUCCESS: ROC image %s saved.\", roc_image_name)\n",
    "    except AssertionError:\n",
    "        logging.error(\n",
    "            \"ERROR: ROC image %s not found in path %s\",\n",
    "            roc_image_name,\n",
    "            image_path,\n",
    "        )\n",
    "\n",
    "    # Check if Feature Importance image exists\n",
    "    feature_importance_image_name = \"feature_importance.png\"\n",
    "    try:\n",
    "        image_path = os.getcwd() + config[\"main\"][\"modeling\"][\"output_dir\"]\n",
    "        assert check_file_exists(image_path, feature_importance_image_name)\n",
    "        logging.info(\n",
    "            \"SUCCESS: Feature importance image %s saved.\",\n",
    "            feature_importance_image_name,\n",
    "        )\n",
    "    except AssertionError:\n",
    "        logging.error(\n",
    "            \"ERROR: Feature importance image %s not found in path %s\",\n",
    "            feature_importance_image_name,\n",
    "            image_path,\n",
    "        )\n",
    "\n",
    "    # Check if model evaluation file exists\n",
    "    model_eval_file_name = \"slice_output.txt\"\n",
    "    try:\n",
    "        image_path = os.getcwd() + config[\"main\"][\"modeling\"][\"output_dir\"]\n",
    "        assert check_file_exists(image_path, model_eval_file_name)\n",
    "        logging.info(\n",
    "            \"SUCCESS: Model evaluation metrics %s saved.\", model_eval_file_name\n",
    "        )\n",
    "    except AssertionError:\n",
    "        logging.error(\n",
    "            \"ERROR: Model evaluation metrics %s not found in path %s\",\n",
    "            model_eval_file_name,\n",
    "            image_path,\n",
    "        )\n",
    "\n",
    "    # Check if overall evaluation file exists\n",
    "    overall_eval_file_name = \"model_metrics.csv\"\n",
    "    try:\n",
    "        image_path = os.getcwd() + config[\"main\"][\"modeling\"][\"output_dir\"]\n",
    "        assert check_file_exists(image_path, overall_eval_file_name)\n",
    "        logging.info(\n",
    "            \"SUCCESS: Overall model evaluation metrics %s saved.\",\n",
    "            overall_eval_file_name,\n",
    "        )\n",
    "    except AssertionError:\n",
    "        logging.error(\n",
    "            \"ERROR: Overall model evaluation metrics %s not found in path %s\",\n",
    "            overall_eval_file_name,\n",
    "            image_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "116c9a84-d754-4be7-962f-7c45e26b264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 11:48:44,116 Creating model pipeline\n",
      "2024-12-30 11:48:44,119 Training XGBClassifier model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 11:50:23,284 ERROR: Model training/evaluating failed. run_evaluate_model() missing 2 required positional arguments: 'best_model' and 'X'\n",
      "2024-12-30 11:50:23,285 SUCCESS: Best model best_model.pkl is saved.\n",
      "2024-12-30 11:50:23,286 SUCCESS: ROC image roc_curve.png saved.\n",
      "2024-12-30 11:50:23,286 SUCCESS: Feature importance image feature_importance.png saved.\n",
      "2024-12-30 11:50:23,287 SUCCESS: Model evaluation metrics slice_output.txt saved.\n",
      "2024-12-30 11:50:23,287 SUCCESS: Overall model evaluation metrics model_metrics.csv saved.\n"
     ]
    }
   ],
   "source": [
    "test_train_and_evaluate_model(X_train, X_val, y_train, y_val, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
